{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 06 â€” Model Interpretability\n",
        "\n",
        "**Feature importance, SHAP values, and party deviation analysis**\n",
        "\n",
        "Export findings for the research paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "Path(\"../outputs\").mkdir(exist_ok=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from src.ml.features import load_pairs, get_train_val_test, build_basic_features, add_enhanced_features\n",
        "from src.ml.models import train_model_a, predict_model_a, build_X_for_model_a\n",
        "\n",
        "MODEL_KW = dict(\n",
        "    max_features=2000, ngram_range=(1, 1), min_df=1,\n",
        "    use_besluit_tfidf=True, use_speech_position=True, use_speaker_loyalty=True,\n",
        "    use_kabinetsappreciatie=True, use_zaak_soort=True, use_is_coalition=True,\n",
        ")\n",
        "\n",
        "df = load_pairs(sample=50000)\n",
        "df = df[df[\"datum\"].notna()]\n",
        "df = build_basic_features(df)\n",
        "train, val, test = get_train_val_test(df)\n",
        "train = train[train[\"vote\"].isin([\"Voor\", \"Tegen\"])]\n",
        "val = val[val[\"vote\"].isin([\"Voor\", \"Tegen\"])]\n",
        "train, val, test = add_enhanced_features(train, val, test)\n",
        "\n",
        "model = train_model_a(train, **MODEL_KW)\n",
        "\n",
        "print(f\"Train: {len(train):,} | Val: {len(val):,} | Test: {len(test):,}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Feature Importance (Logistic Regression Coefficients)\n",
        "\n",
        "Which words drive the model toward Voor vs Tegen?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "coef = model[\"clf\"].coef_[0]\n",
        "n_party = len(model[\"party_enc\"].get_feature_names_out())\n",
        "tfidf_names = model[\"tfidf\"].get_feature_names_out()\n",
        "n_tfidf = len(tfidf_names)\n",
        "\n",
        "tfidf_coef = coef[n_party : n_party + n_tfidf]\n",
        "top_voor = np.argsort(tfidf_coef)[-15:][::-1]\n",
        "top_tegen = np.argsort(tfidf_coef)[:15]\n",
        "\n",
        "print(\"Top terms predicting VOOR:\")\n",
        "for i in top_voor:\n",
        "    print(f\"  {tfidf_names[i]}: {tfidf_coef[i]:.3f}\")\n",
        "print(\"\\nTop terms predicting TEGEN:\")\n",
        "for i in top_tegen:\n",
        "    print(f\"  {tfidf_names[i]}: {tfidf_coef[i]:.3f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
        "axes[0].barh(range(15), tfidf_coef[top_voor], color=\"green\", alpha=0.7)\n",
        "axes[0].set_yticks(range(15))\n",
        "axes[0].set_yticklabels([tfidf_names[i] for i in top_voor], fontsize=9)\n",
        "axes[0].set_title(\"Pro-Voor terms\")\n",
        "axes[0].invert_yaxis()\n",
        "axes[1].barh(range(15), tfidf_coef[top_tegen], color=\"red\", alpha=0.7)\n",
        "axes[1].set_yticks(range(15))\n",
        "axes[1].set_yticklabels([tfidf_names[i] for i in top_tegen], fontsize=9)\n",
        "axes[1].set_title(\"Pro-Tegen terms\")\n",
        "axes[1].invert_yaxis()\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../outputs/06_feature_importance.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. SHAP Values (Per-Prediction Explanations)\n",
        "\n",
        "\"This speech predicted Tegen because of words X, Y, Z\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "try:\n",
        "    import shap\n",
        "\n",
        "    X_val = build_X_for_model_a(val, model)\n",
        "    if hasattr(X_val, \"toarray\"):\n",
        "        X_val = X_val.toarray()\n",
        "\n",
        "    explainer = shap.LinearExplainer(model[\"clf\"], X_val)\n",
        "    shap_values = explainer.shap_values(X_val[:100])\n",
        "\n",
        "    feature_names = (\n",
        "        list(model[\"party_enc\"].get_feature_names_out())\n",
        "        + list(model[\"tfidf\"].get_feature_names_out())\n",
        "    )\n",
        "    if model.get(\"tfidf_besluit\") is not None:\n",
        "        feature_names += list(model[\"tfidf_besluit\"].get_feature_names_out())\n",
        "    if model.get(\"use_speech_position\"):\n",
        "        feature_names.append(\"speech_position\")\n",
        "    if model.get(\"use_speaker_loyalty\"):\n",
        "        feature_names.append(\"speaker_loyalty\")\n",
        "    if model.get(\"use_kabinetsappreciatie\") and model.get(\"ka_enc\") is not None:\n",
        "        feature_names += list(model[\"ka_enc\"].get_feature_names_out())\n",
        "    if model.get(\"use_zaak_soort\") and model.get(\"zs_enc\") is not None:\n",
        "        feature_names += list(model[\"zs_enc\"].get_feature_names_out())\n",
        "    if model.get(\"use_is_coalition\"):\n",
        "        feature_names.append(\"is_coalition\")\n",
        "    feature_names = feature_names[:X_val.shape[1]]\n",
        "\n",
        "    shap.summary_plot(shap_values, X_val[:100], feature_names=feature_names[:50], show=False)\n",
        "    plt.title(\"SHAP values for vote prediction (top 50 features)\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"../outputs/06_shap_summary.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "except ImportError:\n",
        "    print(\"Install shap: pip install shap\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Party Deviation Analysis\n",
        "\n",
        "Which speakers' speech most diverges from their party's voting pattern?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "val_copy = val.copy()\n",
        "val_copy[\"pred\"] = predict_model_a(model, val)\n",
        "val_copy[\"correct\"] = val_copy[\"vote\"] == val_copy[\"pred\"]\n",
        "\n",
        "party_majority = model[\"party_enc\"].get_feature_names_out()\n",
        "party_acc = val_copy.groupby(\"fractie\").agg(\n",
        "    total=(\"correct\", \"count\"),\n",
        "    correct=(\"correct\", \"sum\"),\n",
        ")\n",
        "party_acc[\"accuracy\"] = party_acc[\"correct\"] / party_acc[\"total\"]\n",
        "party_acc = party_acc[party_acc[\"total\"] >= 5].sort_values(\"accuracy\")\n",
        "\n",
        "print(\"Parties where speech-based model diverges most from party (lowest accuracy):\")\n",
        "print(party_acc.head(10).to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "speaker_dev = val_copy.groupby([\"persoon_id\", \"achternaam\", \"fractie\"]).agg(\n",
        "    total=(\"correct\", \"count\"),\n",
        "    correct=(\"correct\", \"sum\"),\n",
        ")\n",
        "speaker_dev[\"accuracy\"] = speaker_dev[\"correct\"] / speaker_dev[\"total\"]\n",
        "speaker_dev = speaker_dev[speaker_dev[\"total\"] >= 3].sort_values(\"accuracy\")\n",
        "\n",
        "print(\"\\nSpeakers whose speech most diverges from prediction (lowest accuracy):\")\n",
        "print(speaker_dev.head(15).to_string())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Linking Quality Analysis\n",
        "\n",
        "How well does the speech-vote linking work? Check coverage of Kabinetsappreciatie and Zaak.Soort."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Linking quality: coverage of enriched features\n",
        "if \"kabinetsappreciatie\" in train.columns:\n",
        "    ka_dist = train[\"kabinetsappreciatie\"].fillna(\"Onbekend\").value_counts()\n",
        "    print(\"Kabinetsappreciatie distribution (train):\")\n",
        "    print(ka_dist.head(10).to_string())\n",
        "if \"zaak_soort\" in train.columns:\n",
        "    zs_dist = train[\"zaak_soort\"].fillna(\"Onbekend\").value_counts()\n",
        "    print(\"\\nZaak.Soort distribution (train):\")\n",
        "    print(zs_dist.head(10).to_string())\n",
        "if \"agendapunt_onderwerp\" in train.columns:\n",
        "    has_topic = train[\"agendapunt_onderwerp\"].notna() & (train[\"agendapunt_onderwerp\"].astype(str).str.len() > 5)\n",
        "    print(f\"\\nPairs with non-empty agendapunt_onderwerp: {has_topic.sum():,} / {len(train):,} ({100*has_topic.mean():.1f}%)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. RobBERT Evaluation (if checkpoint exists)\n",
        "\n",
        "Load the fine-tuned RobBERT transformer and evaluate on validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "from src.ml.models import load_model_robbert, predict_model_robbert, evaluate\n",
        "\n",
        "robbert_path = Path(\"../models/robbert_vote_classifier\")\n",
        "if (robbert_path / \"config.json\").exists():\n",
        "    model_robbert = load_model_robbert(str(robbert_path))\n",
        "    pred_robbert = predict_model_robbert(model_robbert, val)\n",
        "    r_robbert = evaluate(val[\"vote\"].values, pred_robbert)\n",
        "    print(f\"RobBERT val accuracy: {r_robbert['accuracy']*100:.1f}%\")\n",
        "    print(f\"RobBERT F1 (macro): {r_robbert['f1_macro']:.3f}\")\n",
        "else:\n",
        "    print(\"RobBERT checkpoint not found. Run: python scripts/train_robbert.py --epochs 5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. RobBERT Attention Visualization\n",
        "\n",
        "Which tokens does the model attend to for a given prediction? (Requires RobBERT checkpoint.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if (robbert_path / \"config.json\").exists():\n",
        "    from src.ml.models import get_robbert_attention\n",
        "\n",
        "    sample_row = val.iloc[10]\n",
        "    cls_attn, tokens, pred = get_robbert_attention(model_robbert, sample_row)\n",
        "    # Plot top tokens by CLS attention (skip [CLS] and [SEP])\n",
        "    n_show = min(25, len(tokens))\n",
        "    idx = np.argsort(cls_attn)[::-1][:n_show]\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    y_pos = np.arange(n_show)\n",
        "    ax.barh(y_pos, cls_attn[idx], color=\"steelblue\", alpha=0.8)\n",
        "    ax.set_yticks(y_pos)\n",
        "    ax.set_yticklabels([tokens[i] for i in idx], fontsize=9)\n",
        "    ax.invert_yaxis()\n",
        "    ax.set_xlabel(\"CLS attention weight\")\n",
        "    ax.set_title(f\"RobBERT: tokens most attended to (prediction: {pred})\")\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"../outputs/06_robbert_attention.png\", dpi=150, bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"RobBERT checkpoint not found. Skip attention visualization.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "party_acc_plot = party_acc.tail(15)\n",
        "colors = [\"green\" if a > 0.7 else \"orange\" if a > 0.5 else \"red\" for a in party_acc_plot[\"accuracy\"]]\n",
        "ax.barh(party_acc_plot.index, party_acc_plot[\"accuracy\"], color=colors, alpha=0.7)\n",
        "ax.axvline(0.5, color=\"gray\", linestyle=\"--\")\n",
        "ax.set_xlabel(\"Accuracy (speech model vs actual vote)\")\n",
        "ax.set_title(\"Party deviation: model accuracy by party\")\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"../outputs/06_party_deviation.png\", dpi=150, bbox_inches=\"tight\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}